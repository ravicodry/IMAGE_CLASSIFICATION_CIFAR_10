# -*- coding: utf-8 -*-
"""Image_Classification_CIFAR10_DATASET.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pUAcBkwxI91oynoZVvlxCqnCseffGHyf
"""

# import neccessary library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import datasets,layers,models

"""Load the dataset

"""

(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()

X_train.shape

"""# shape of train and test file"""

X_train.shape

"""Each image is 32px by 32px and each pixel contains 3 dimensions (R, G, B). Each value is the brightness of the corresponding color between 0 and 255."""

X_train[0]

X_test.shape

"""50000 training images and 1000 test images

"""

y_train.shape

plt.imshow(X_train[19])

y_train1D=y_train.reshape(-1,)

y_train1D.shape

y_train1D

"""There are 10 classes in this datasets

"""

classes=["airplane","automobile","bird","cat","deer","dog","frog","horse","ship","truck"]

"""let define a function to study and plot the respective index image"""

def img_plot(X,y,index):
  plt.figure(figsize=(8,4))
  plt.imshow(X[index])
  plt.xlabel(classes[y[index]])
for i in range(10):
     img_plot(X_train,y_train1D,i)

"""Normalize datasets for better perfromance.

 Rescale the images to obtain the range [0, 1] by dividing by 255 (the maximum value of the pixels).
"""

X_train = X_train / 255.0
X_test = X_test / 255.0

"""MLP"""

from keras.models import Sequential
from keras.layers import Dense,Flatten

# define the model
model = Sequential()
model.add(Flatten(input_shape = X_train.shape[1:]))
model.add(Dense(3000, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.summary()

# compile the model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', 
                  metrics=['accuracy'])

X_train.shape

y_train

y_train.shape

mlp = model.fit(X_train, y_train, epochs=6)

hist=mlp.history

#accuracy of the model
print("Accuracy of the MLP model in each epoch is :",hist['accuracy'])
print("loss of the MLP model in eah epoch is :",hist['loss'])
print("final accuracy of the MLP model: ",round((hist['accuracy'][-1]),2)*100 )

"""model.evaluate(): To calculate the loss values for input data.

model.predict(): To generate network output for input data.

model.predict_classes(): To generate class outputs for input data.

model.predict_proba(): To generate class probabilities for input data.

Evaluation:
"""

mlp
#mlp_score = hist.predict(X_test)
#print('\n', 'Test accuracy:', mlp_score)

"""ANN for classification"""

ann = models.Sequential([
        layers.Flatten(input_shape=(32,32,3)),
        layers.Dense(3000, activation='relu'),
        layers.Dense(1000, activation='relu'),
        layers.Dense(10, activation='sigmoid')    
    ])

ann.compile(optimizer='SGD',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

ann.fit(X_train, y_train, epochs=5)

from sklearn.metrics import confusion_matrix,classification_report
y_pred=ann.predict(X_test)
y_pred_per_class=[np.argmax(a) for a in y_pred]
print("classification report: ",classification_report(y_test,y_pred_per_class))

"""Convolutional Neural Network"""

cnn = models.Sequential([
    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

cnn.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

cnn.fit(X_train, y_train, epochs=10)

y_pred_cnn=cnn.predict(X_test)
y_pred_cnn

y_pred_cnn_class=[np.argmax(b) for b in y_pred_cnn]
print("classification_report: ", classification_report(y_test,y_pred_cnn_class))